@article{DBLP:journals/corr/HuangLW16a,
  author    = {Gao Huang and
               Zhuang Liu and
               Kilian Q. Weinberger},
  title     = {Densely Connected Convolutional Networks},
  journal   = {CoRR},
  volume    = {abs/1608.06993},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.06993},
  archivePrefix = {arXiv},
  eprint    = {1608.06993},
  timestamp = {Wed, 07 Jun 2017 14:42:40 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HuangLW16a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{KhoslaYaoJayadevaprakashFeiFei_FGVC2011,
author = "Aditya Khosla and Nityananda Jayadevaprakash and Bangpeng Yao and Li Fei-Fei",
title = "Novel Dataset for Fine-Grained Image Categorization",
booktitle = "First Workshop on Fine-Grained Visual Categorization, IEEE Conference on Computer Vision and Pattern Recognition",
year = "2011",
month = "June",
address = "Colorado Springs, CO",
}


@article{LeCun:1989:BAH:1351079.1351090,
 author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
 title = {Backpropagation Applied to Handwritten Zip Code Recognition},
 journal = {Neural Comput.},
 issue_date = {Winter 1989},
 volume = {1},
 number = {4},
 month = dec,
 year = {1989},
 issn = {0899-7667},
 pages = {541--551},
 numpages = {11},
 url = {http://dx.doi.org/10.1162/neco.1989.1.4.541},
 doi = {10.1162/neco.1989.1.4.541},
 acmid = {1351090},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@INPROCEEDINGS{Lecun98gradient-basedlearning,
    author = {Yann Lecun and LÃ©on Bottou and Yoshua Bengio and Patrick Haffner},
    title = {Gradient-based learning applied to document recognition},
    booktitle = {Proceedings of the IEEE},
    year = {1998},
    pages = {2278--2324}
}

@article{DBLP:journals/corr/RussakovskyDSKSMHKKBBF14,
  author    = {Olga Russakovsky and
               Jia Deng and
               Hao Su and
               Jonathan Krause and
               Sanjeev Satheesh and
               Sean Ma and
               Zhiheng Huang and
               Andrej Karpathy and
               Aditya Khosla and
               Michael S. Bernstein and
               Alexander C. Berg and
               Fei{-}Fei Li},
  title     = {ImageNet Large Scale Visual Recognition Challenge},
  journal   = {CoRR},
  volume    = {abs/1409.0575},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.0575},
  archivePrefix = {arXiv},
  eprint    = {1409.0575},
  timestamp = {Wed, 07 Jun 2017 14:41:16 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/RussakovskyDSKSMHKKBBF14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/LarssonMS16a,
  author    = {Gustav Larsson and
               Michael Maire and
               Gregory Shakhnarovich},
  title     = {FractalNet: Ultra-Deep Neural Networks without Residuals},
  journal   = {CoRR},
  volume    = {abs/1605.07648},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.07648},
  archivePrefix = {arXiv},
  eprint    = {1605.07648},
  timestamp = {Wed, 07 Jun 2017 14:41:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LarssonMS16a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{NIPS2015_5850,
title = {Training Very Deep Networks},
author = {Srivastava, Rupesh K and Greff, Klaus and Schmidhuber, J\"{u}rgen},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {2377--2385},
year = {2015},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5850-training-very-deep-networks.pdf}
}

@article{DBLP:journals/corr/JegouDVRB16,
  author    = {Simon J{\'{e}}gou and
               Michal Drozdzal and
               David V{\'{a}}zquez and
               Adriana Romero and
               Yoshua Bengio},
  title     = {The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for
               Semantic Segmentation},
  journal   = {CoRR},
  volume    = {abs/1611.09326},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.09326},
  archivePrefix = {arXiv},
  eprint    = {1611.09326},
  timestamp = {Wed, 07 Jun 2017 14:40:48 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/JegouDVRB16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ BrostowSFC:ECCV08,
  author    = {Gabriel J. Brostow and Jamie Shotton and Julien Fauqueur and Roberto Cipolla},
  title     = {Segmentation and Recognition Using Structure from Motion Point Clouds},
  booktitle = {ECCV (1)},
  year      = {2008},
  pages     = {44-57}
}
 

@article{cifar100,
title= {CIFAR-100 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
abstract= {This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a "fine" label (the class to which it belongs) and a "coarse" label (the superclass to which it belongs).
Here is the list of classes in the CIFAR-100:

Superclass	Classes
aquatic mammals	beaver, dolphin, otter, seal, whale
fish	aquarium fish, flatfish, ray, shark, trout
flowers	orchids, poppies, roses, sunflowers, tulips
food containers	bottles, bowls, cans, cups, plates
fruit and vegetables	apples, mushrooms, oranges, pears, sweet peppers
household electrical devices	clock, computer keyboard, lamp, telephone, television
household furniture	bed, chair, couch, table, wardrobe
insects	bee, beetle, butterfly, caterpillar, cockroach
large carnivores	bear, leopard, lion, tiger, wolf
large man-made outdoor things	bridge, castle, house, road, skyscraper
large natural outdoor scenes	cloud, forest, mountain, plain, sea
large omnivores and herbivores	camel, cattle, chimpanzee, elephant, kangaroo
medium-sized mammals	fox, porcupine, possum, raccoon, skunk
non-insect invertebrates	crab, lobster, snail, spider, worm
people	baby, boy, girl, man, woman
reptiles	crocodile, dinosaur, lizard, snake, turtle
small mammals	hamster, mouse, rabbit, shrew, squirrel
trees	maple, oak, palm, pine, willow
vehicles 1	bicycle, bus, motorcycle, pickup truck, train
vehicles 2	lawn-mower, rocket, streetcar, tank, tractor

Yes, I know mushrooms aren't really fruit or vegetables and bears aren't really carnivores. },
keywords= {Dataset},
terms= {}
}

@inproceedings{37648,
title = {Reading Digits in Natural Images with Unsupervised Feature Learning},
author  = {Yuval Netzer and Tao Wang and Adam Coates and Alessandro Bissacco and Bo Wu and Andrew Y. Ng},
year  = {2011},
URL = {http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf},
booktitle = {NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011}
}

@article{DBLP:journals/corr/SzegedyLJSRAEVR14,
  author    = {Christian Szegedy and
               Wei Liu and
               Yangqing Jia and
               Pierre Sermanet and
               Scott E. Reed and
               Dragomir Anguelov and
               Dumitru Erhan and
               Vincent Vanhoucke and
               Andrew Rabinovich},
  title     = {Going Deeper with Convolutions},
  journal   = {CoRR},
  volume    = {abs/1409.4842},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.4842},
  archivePrefix = {arXiv},
  eprint    = {1409.4842},
  timestamp = {Wed, 07 Jun 2017 14:40:42 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SzegedyLJSRAEVR14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/PleissCHLMW17,
  author    = {Geoff Pleiss and
               Danlu Chen and
               Gao Huang and
               Tongcheng Li and
               Laurens van der Maaten and
               Kilian Q. Weinberger},
  title     = {Memory-Efficient Implementation of DenseNets},
  journal   = {CoRR},
  volume    = {abs/1707.06990},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06990},
  archivePrefix = {arXiv},
  eprint    = {1707.06990},
  timestamp = {Sat, 05 Aug 2017 14:56:07 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/PleissCHLMW17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{Lafferty:2001:CRF:645530.655813,
 author = {Lafferty, John D. and McCallum, Andrew and Pereira, Fernando C. N.},
 title = {Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data},
 booktitle = {Proceedings of the Eighteenth International Conference on Machine Learning},
 series = {ICML '01},
 year = {2001},
 isbn = {1-55860-778-1},
 pages = {282--289},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=645530.655813},
 acmid = {655813},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 


@article{CIFAR10,
title= {CIFAR-10 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
abstract= {The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. },
keywords= {Dataset},
terms= {}
}
